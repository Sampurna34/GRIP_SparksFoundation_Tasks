# Task 2- Explore Supervised Machine Learning

# Data:  

###### Given number of hours a student have studied and their respective scores.

# Objective:

###### To predict the percentage of marks that a student is expected to score based upon the number of hours they studied 

## Dataset:

http://bit.ly/w-data

# Importing all libraries required in this notebook
import pandas as pd
import statistics as st
import numpy as np  
import matplotlib.pyplot as plt  
%matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import math
from scipy import stats

# Reading the data
data=pd.read_csv("C:\SamFiles\INTERNASHALA TRAINING\SPARKS Foundation\Task 2\student_scores - student_scores.csv")

print(data)
print("Data Readed Succesfully")

# Basic statistics of the dataset

data.describe()

###### The mean hours of study is 5 hours and mean percentage score is 51.48%

corr=data.corr()
corr

plt.figure(figsize=(16,10))
sns.heatmap(corr,cmap="YlGnBu")

# Data visualization

# Plotting the Hours vs. Scores scatter plot
data.plot(x='Hours', y='Scores', style='o')  
plt.title('Hours vs Percentage')  
plt.xlabel('Hours Studied')  
plt.ylabel('Percentage Score')  
plt.show()

###### The correlation heat map and the scatter plot shows that there is a strong positive correlation and linear relationship between the hours studied and the scores of the students

sns.pairplot(data, diag_kind='kde')

# Plotting the distribution of scores
sns.distplot(data['Scores'])

###### The frequency distribution graph shows that the scores are almost normally distributed

# Plotting the distribution of scores
sns.distplot(data['Hours'])

## Preparing the data

# Dividing the data into "attributes" (inputs) and "labels" (outputs)
X = data.iloc[:, :-1].values  
y = data.iloc[:, 1].values 

# Splitting this data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) 

## Training the Model Algorithm

# Using train dataset to fit a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)
print('Training Successful')

#### Plotting the regression line

y=ax+b



# Plotting for the trained and tested data
fig = plt.figure(figsize =(10,10))
mx1 = plt.subplot(221)
mx2 = plt.subplot(222)

line = model.coef_*X+model.intercept_

mx1.scatter(X,y)
mx1.plot(X,line)
plt.show
mx1.set_title('Trained Set')
mx1.set_xlabel('Hours')
mx1.set_ylabel('Scores')

mx2.scatter(X_test, y_test)
mx2.plot(X_train, model.predict(X_train), c="orange")
mx2.set_title('Tested Set')
mx2.set_xlabel('Hours')
mx2.set_ylabel('Scores')
plt.show

## Model Predictions

#Comapring Observed and Predicted values
y_pred = model.predict(X_test)
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df

# Plotting the prediction with actual values
df.plot(kind = 'bar', figsize=(10,8))
plt.xlabel('Hours')  
plt.ylabel('Scores')  

### Predicting own score of a student according to the hours studied

hours = float(input('Enter the no. of hours:'))
pred_own_score = model.predict([[hours]])
print("Number of Hours = {}".format(hours))
print("Predicted Score = {}".format(pred_own_score[0]))

# Evaluating the Model Performance

Using 2 methods:
R-square
 and Root Mean Square Error (RMSE)

#R-square value
slope , intercept, r, p, std_err = stats.linregress(y_test, y_pred)
print('R-Squared error:',r)

###### We can infer from the R-square value that the model explains 98% of the variability in the dependent variable by the independent variable

#Root Mean Square Error value
print(mean_squared_error(y_test, y_pred))
print(math.sqrt(mean_squared_error(y_test, y_pred)))


